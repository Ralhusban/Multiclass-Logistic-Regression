{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 9908,
     "status": "ok",
     "timestamp": 1579577165003,
     "user": {
      "displayName": "Kanchana Padmanabhan",
      "photoUrl": "",
      "userId": "16906781817953159303"
     },
     "user_tz": 300
    },
    "id": "kHSNOAUmHYyi",
    "outputId": "0b70c361-9579-4114-92ea-32fc00582aab"
   },
   "outputs": [],
   "source": [
    "#!pip install sklearn\n",
    "#!pip install pandas\n",
    "#!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "id": "P8z-WKOwHeiu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WvgfwPPI6h3"
   },
   "source": [
    "### **Iris Dataset (Sample Dataset)**\n",
    "Popular classification dataset with 3 classes; setosa, virginica and versicolor.\n",
    "\n",
    "```\n",
    "https://en.wikipedia.org/wiki/Iris_flower_data_set\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "id": "1xrjwZi1H905"
   },
   "outputs": [],
   "source": [
    "iris_data = load_iris(return_X_y=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "id": "EwWdbdFQIR79"
   },
   "outputs": [],
   "source": [
    "df_iris = pd.DataFrame(data= np.c_[iris_data['data'], iris_data['target']],\n",
    "                     columns= iris_data['feature_names'] + ['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 642,
     "status": "ok",
     "timestamp": 1579579427196,
     "user": {
      "displayName": "Kanchana Padmanabhan",
      "photoUrl": "",
      "userId": "16906781817953159303"
     },
     "user_tz": 300
    },
    "id": "j-pRBUiTJ3bT",
    "outputId": "06ae64e7-8c29-4d76-a7a1-00e61c4178c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
       "       'petal width (cm)', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iris.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris_sample=df_iris.sample(frac=1).reset_index(drop=True) # Shuffle the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "id": "HBwwPIn6KPGX"
   },
   "outputs": [],
   "source": [
    "X = df_iris_sample[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n",
    "       'petal width (cm)']].to_numpy()\n",
    "y = df_iris_sample[['target']].to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding for the labels in preparation to passing them thru our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc=OneHotEncoder(sparse=False)\n",
    "y=enc.fit_transform(y.reshape(len(y),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 70-30 Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70/30 train-test split for our dataset\n",
    "X_train=X[:int(len(X)*0.7)]\n",
    "X_test=X[int(len(X)*0.7):]\n",
    "y_train=y[:int(len(y)*0.7)]\n",
    "y_test=y[int(len(y)*0.7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax function - note the subtraction of the max value from the array, which is done to avoid overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax function\n",
    "def softmax(x):\n",
    "    return np.exp(x-x.max())/ np.sum(np.exp(x-x.max()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial steps before forward propagation\n",
    "\n",
    "cost_list=[] #List of costs for plotting\n",
    "epochs=500 # Number of iterations\n",
    "epsilon=1 # Divergence criterea, in otherwords the loop will end when the change in the cost will be less that this value  \n",
    "actual_iters=0 # For plotting the actual number of epochs if divergence occurs prior to the number of max epochs\n",
    "K=y.shape[1] # Number of unique classes\n",
    "W=np.random.randint(low=-100,high=100,size=(X_train.shape[1]+1, K))/1000 #Random initilization of weight vector in addition to bias to keep it in one vector \n",
    "dc_dw=np.zeros_like(W) # Initialize and empty dc/dw array which will be used in the gradient descent to adjust the weight vectors. \n",
    "eta=0.01 # Learning rate\n",
    "x0=np.repeat(1, len(X_train)) # Generating an additional feature of 1s that will be concatinated to the dataset, which will help with bias calculation\n",
    "new_x= np.c_[x0,X_train] # The feature of 1s is added to the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward propagation\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    # Note that the bias (b) is already taken into account as its combined in the weight vector. Recall that we added a column of 1s to the training set \n",
    "    # and would be plugged in during the matrix multiplication.\n",
    "    o=W.T@new_x.T\n",
    "    y=softmax(o)\n",
    "    cost= -np.sum(y_train.T*np.log(y)) #Cost function\n",
    "    cost_list.append(cost) # We append the cost to a list for plotting purposes\n",
    "\n",
    "    #print(cost)\n",
    "    if len(cost_list)>100:\n",
    "        if abs(cost_list[-1]-cost_list[-2])<epsilon:\n",
    "            break\n",
    "    actual_iters+=1  \n",
    "    \n",
    "        #Backpropagation\n",
    "\n",
    "    for j in range(K):\n",
    "        dc_dw[:,j]=np.sum(((y_train[:,j]-y[j,:]))*new_x.T, axis=1)\n",
    "        W[:,j]+=eta*dc_dw[:,j]\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-182-f61861395cbe>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-182-f61861395cbe>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    plt.xlabel('Iterations - Epochs')\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print('W',W) # Printing the weights\n",
    "# Plotting the cost over epochs\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.title('Converged after '+str(actual_iters)+' iterations')\n",
    "plt.plot(range(len(cost_list), cost_list, 'r--', label='Cost')\n",
    "plt.xlabel('Iterations - Epochs')\n",
    "plt.ylabel('Error / Cost')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that the model converged after 281 iterations as $\\Delta$ L(w,j) was lower than threshold $\\epsilon$ =3e-3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the resulting W, b (one vector) to the test data\n",
    "x0=np.repeat(1, len(X_test)) # Generating an additional feature of 1s that will be concatinated to the dataset, which will help with bias calculation\n",
    "X_test= np.c_[x0,X_test] # The feature of 1s is added to the matrix\n",
    "W=np.squeeze(W) # Get rid of single dimentional entries. In this case a [[n0,...,nm]] becomes [n0,...nm] - easier for coding\n",
    "predictions=np.round((softmax(W.T@X_test.T)),3)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We transpose predictions to help visualize the softmax output for the three classes. Softmax helps us minimize the value of the wrong classes and maximize the ones of the correct classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.T "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use a simple numpy method (np.where) to transform the model prediction to the respective classes by identifiying the values >0.50 as 1 and 0 otherwise. You are free to adjust this threshold as needed. We plug that result and compare it with the truth labels of our test set and make a simple calculation to determine the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compare the results with the original test labels and see 100% accuracy for our logistic regression model\n",
    "accuracy=(np.where(predictions<0.5, 0,1)).T==y_test\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will only consider an output correct if the three labels predicted by the model match the ground truth labels of the test set, hence the use of result.all()==True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report on model accuracy\n",
    "ctr=0\n",
    "for result in accuracy:\n",
    "    if result.all()==True:\n",
    "        ctr+=1\n",
    "print('Model accuracy is', ctr/len(accuracy)*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you want to check the actual labels, simply use the inverse_transform function of the OneHotEncoder instance we trained eariler. See the example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.inverse_transform(predictions.T)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPsrRJHObx8vftyVwUhWGQe",
   "collapsed_sections": [],
   "name": "Homework 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
